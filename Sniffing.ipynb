{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032dce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scapy==2.5.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'scapy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'scapy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading scapy-2.5.0.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 0.5/1.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 0.8/1.3 MB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.0/1.3 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.3/1.3 MB 1.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: scapy\n",
      "  Building wheel for scapy (setup.py): started\n",
      "  Building wheel for scapy (setup.py): finished with status 'done'\n",
      "  Created wheel for scapy: filename=scapy-2.5.0-py2.py3-none-any.whl size=1444458 sha256=ea13502489a8077f3e05d5df61061c6b8c0071f6c97b75de8b9eec8a1fd5d2de\n",
      "  Stored in directory: c:\\users\\kimo store\\appdata\\local\\pip\\cache\\wheels\\82\\b7\\03\\8344d8cf6695624746311bc0d389e9d05535ca83c35f90241d\n",
      "Successfully built scapy\n",
      "Installing collected packages: scapy\n",
      "Successfully installed scapy-2.5.0\n"
     ]
    }
   ],
   "source": [
    "# pip install scapy==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ba892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import sniff, TCP, UDP, IP\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import time\n",
    "import csv\n",
    "import joblib\n",
    "import socket\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef794ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and transformers\n",
    "model = load_model(\"dnn_ids_model.h5\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "le_protocol = joblib.load(\"le_protocol.pkl\")\n",
    "le_service = joblib.load(\"le_service.pkl\")\n",
    "le_flag = joblib.load(\"le_flag.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bc9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"features_prediction_log.csv\"\n",
    "FLOW_TIMEOUT = 10\n",
    "flows = defaultdict(list)\n",
    "flow_start_time = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dacd85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header based on extractable features + prediction\n",
    "HEADERS = [\n",
    "    'timestamp', 'src', 'dst', 'sport', 'dport',\n",
    "    'protocol_type', 'service', 'flag',\n",
    "    'duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent',\n",
    "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
    "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "    'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate', 'prediction'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd868bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service(port):\n",
    "    try:\n",
    "        return socket.getservbyport(port)\n",
    "    except:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92532497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow_features(flow_key, pkts):\n",
    "    src, dst, sport, dport, proto = flow_key\n",
    "    start_time = pkts[0].time\n",
    "    end_time = pkts[-1].time\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    src_bytes = sum(len(p) for p in pkts if IP in p and p[IP].src == src)\n",
    "    dst_bytes = sum(len(p) for p in pkts if IP in p and p[IP].src == dst)\n",
    "\n",
    "    service = get_service(dport)\n",
    "    land = int(src == dst and sport == dport)\n",
    "    urgent = sum(1 for p in pkts if TCP in p and p[TCP].flags & 0x20)\n",
    "    wrong_fragment = sum(1 for p in pkts if IP in p and (p[IP].frag > 0 or p[IP].flags & 0x1))\n",
    "\n",
    "    flag = 'OTH'\n",
    "    for p in pkts:\n",
    "        if TCP in p:\n",
    "            flag = str(p[TCP].flags)\n",
    "            break\n",
    "\n",
    "    # Partial logic for statistical features (simplified)\n",
    "    count = len(pkts)\n",
    "    serror_rate = sum(1 for p in pkts if TCP in p and 'S' in str(p[TCP].flags) and 'A' not in str(p[TCP].flags)) / count\n",
    "    rerror_rate = sum(1 for p in pkts if TCP in p and 'R' in str(p[TCP].flags)) / count\n",
    "\n",
    "    features = {\n",
    "        'timestamp': datetime.fromtimestamp(end_time).isoformat(),\n",
    "        'src': src, 'dst': dst, 'sport': sport, 'dport': dport,\n",
    "        'protocol_type': proto, 'service': service, 'flag': flag,\n",
    "        'duration': duration, 'src_bytes': src_bytes, 'dst_bytes': dst_bytes,\n",
    "        'land': land, 'wrong_fragment': wrong_fragment, 'urgent': urgent,\n",
    "        'count': count, 'srv_count': count,\n",
    "        'serror_rate': serror_rate, 'srv_serror_rate': serror_rate,\n",
    "        'rerror_rate': rerror_rate, 'srv_rerror_rate': rerror_rate,\n",
    "        'same_srv_rate': 1.0, 'diff_srv_rate': 0.0,\n",
    "        'srv_diff_host_rate': 0.0, 'dst_host_count': 1,\n",
    "        'dst_host_srv_count': 1, 'dst_host_same_srv_rate': 1.0,\n",
    "        'dst_host_diff_srv_rate': 0.0, 'dst_host_same_src_port_rate': 1.0,\n",
    "        'dst_host_srv_diff_host_rate': 0.0,\n",
    "        'dst_host_serror_rate': serror_rate,\n",
    "        'dst_host_srv_serror_rate': serror_rate,\n",
    "        'dst_host_rerror_rate': rerror_rate,\n",
    "        'dst_host_srv_rerror_rate': rerror_rate,\n",
    "    }\n",
    "\n",
    "    # Predict\n",
    "    feature_vector = [\n",
    "        le_protocol.transform([proto])[0] if proto in le_protocol.classes_ else -1,\n",
    "        le_service.transform([service])[0] if service in le_service.classes_ else -1,\n",
    "        le_flag.transform([flag])[0] if flag in le_flag.classes_ else -1,\n",
    "        duration, src_bytes, dst_bytes, land, wrong_fragment, urgent,\n",
    "        count, count, serror_rate, serror_rate,\n",
    "        rerror_rate, rerror_rate, 1.0, 0.0, 0.0, 1, 1,\n",
    "        1.0, 0.0, 1.0, 0.0, serror_rate, serror_rate,\n",
    "        rerror_rate, rerror_rate\n",
    "    ]\n",
    "\n",
    "    feature_vector = scaler.transform([feature_vector])\n",
    "    pred = model.predict(feature_vector)[0][0]\n",
    "    label = 'attack' if pred > 0.5 else 'normal'\n",
    "    features['prediction'] = label\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e24958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header_if_needed():\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, \"x\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=HEADERS)\n",
    "            writer.writeheader()\n",
    "    except FileExistsError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4ff73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_features_to_file(features):\n",
    "    with open(OUTPUT_FILE, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=HEADERS)\n",
    "        writer.writerow(features)\n",
    "\n",
    "def flush_expired_flows():\n",
    "    current_time = time.time()\n",
    "    expired_keys = [k for k, t in flow_start_time.items() if current_time - t > FLOW_TIMEOUT]\n",
    "    for key in expired_keys:\n",
    "        if flows[key]:\n",
    "            features = extract_flow_features(key, flows[key])\n",
    "            log_features_to_file(features)\n",
    "            print(f\"Flow: {features['src']}->{features['dst']} | Prediction: {features['prediction']}\")\n",
    "        del flows[key]\n",
    "        del flow_start_time[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbfa74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_packet(pkt):\n",
    "    if IP in pkt and (TCP in pkt or UDP in pkt):\n",
    "        proto = 'tcp' if TCP in pkt else 'udp'\n",
    "        ip = pkt[IP]\n",
    "        l4 = pkt[TCP] if TCP in pkt else pkt[UDP]\n",
    "        key = (ip.src, ip.dst, l4.sport, l4.dport, proto)\n",
    "\n",
    "        flows[key].append(pkt)\n",
    "        flow_start_time[key] = flow_start_time.get(key, pkt.time)\n",
    "\n",
    "    flush_expired_flows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0f8968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-time Intrusion Detection Started... Press Ctrl+C to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "Flow: 192.168.1.102->20.86.94.195 | Prediction: attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Flow: 192.168.1.102->35.230.116.55 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Flow: 192.168.1.102->74.125.206.188 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Flow: 74.125.206.188->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Flow: 35.230.116.55->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Flow: 20.86.94.195->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Flow: 192.168.1.102->20.52.64.200 | Prediction: attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Flow: 192.168.1.102->20.189.173.3 | Prediction: attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Flow: 20.52.64.200->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Flow: 20.189.173.3->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Flow: 192.168.1.102->20.82.247.142 | Prediction: attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Flow: 20.82.247.142->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Flow: 192.168.1.102->172.217.18.46 | Prediction: attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Flow: 172.217.18.46->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Flow: 208.103.161.1->192.168.1.102 | Prediction: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kimo Store\\anaconda3\\envs\\OLD\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Flow: 192.168.1.102->208.103.161.1 | Prediction: attack\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "write_header_if_needed()\n",
    "print(\"Real-time Intrusion Detection Started... Press Ctrl+C to stop.\")\n",
    "try:\n",
    "    sniff(prn=process_packet, store=False)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping... Flushing remaining flows.\")\n",
    "    for key in list(flows.keys()):\n",
    "        features = extract_flow_features(key, flows[key])\n",
    "        log_features_to_file(features)\n",
    "        print(f\"Flow: {features['src']}->{features['dst']} | Prediction: {features['prediction']}\")\n",
    "    print(\"Finished. Log saved to\", OUTPUT_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
